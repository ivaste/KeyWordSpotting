{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import librosa\n",
    "import numpy as np\n",
    "import Models #Our models\n",
    "import LoadAndPreprocessDataset\n",
    "\n",
    "\n",
    "#categories=['yes','no','up','down','left','right','on','off','stop','go']\n",
    "categories=['yes','no','up','down','left','right','on','off','stop','go','zero','one','two','three','four','five','six','seven','eight','nine','unknown']\n",
    "nCategories=len(categories)\n",
    "nTestSamples=1000 #3k, 11k\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test uses 1000 of 11005 files and occupies 40320000 bytes\n"
     ]
    }
   ],
   "source": [
    "#Load filenames\n",
    "train,val,test = LoadAndPreprocessDataset.loadDatasetFilenames(nCategories=nCategories)\n",
    "\n",
    "#Load TEST file\n",
    "X,y_test=LoadAndPreprocessDataset.loadBatch(test,batch_size=nTestSamples, nCategories=nCategories)\n",
    "#Preprocess TEST\n",
    "#X_test=LoadAndPreprocessDataset.MFCC_DELTA(X,n_mfcc=40)\n",
    "X_test=LoadAndPreprocessDataset.MFCC(X,n_mfcc=40)\n",
    "#X_test=LoadAndPreprocessDataset.melspect(X)\n",
    "#X_test=X\n",
    "\n",
    "#ADD extra dimension for CNN\n",
    "X_test = X_test[..., np.newaxis]\n",
    "\n",
    "\n",
    "print('X_test uses',X_test.shape[0],\"of\",len(test),\"files\",\"and occupies\",X_test.nbytes,\"bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 0.1751 - sparse_categorical_accuracy: 0.9440\n",
      "Entire (ms): 916.2085056304932\n",
      "Average single prediction time (ms): 30.87128210067749\n"
     ]
    }
   ],
   "source": [
    "#load model\n",
    "\n",
    "save_name=\"2020-08-07_12-47_DSConvModel21\"\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('models/'+save_name+'.h5')\n",
    "\n",
    "# Test the model on test data\n",
    "score = model.evaluate(X_test, y_test)\n",
    "y_pred=np.argmax(model.predict(X_test),1)\n",
    "\n",
    "\n",
    "#Measure time for every single prediction\n",
    "import time\n",
    "\n",
    "s=time.time()\n",
    "y_pred=np.argmax(model.predict(X_test[:500,:,:]),1)\n",
    "e=time.time()\n",
    "print(\"Entire (ms):\",(e-s)*1000)\n",
    "\n",
    "starts=np.empty((len(X_test),))\n",
    "ends=np.empty((len(X_test),))\n",
    "for i in range(len(X_test)):\n",
    "    a=np.array([X_test[i]])\n",
    "    starts[i]=time.time()\n",
    "    a=np.argmax(model.predict(a),1)\n",
    "    ends[i]=time.time()\n",
    "average=sum(ends-starts)/len(X_test)\n",
    "print(\"Average single prediction time (ms):\",average*1000)\n",
    "\n",
    "# 1 prediction or a batch of 10 requires the same amount of time\n",
    "# a batch of 100 prediction requires the double of 1\n",
    "# a batch of 500 prediction requires the 3 times of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average single prediction time (ms): 39.65917706489563\n"
     ]
    }
   ],
   "source": [
    "#Measure also with preprocessing\n",
    "\n",
    "\n",
    "#Load filenames\n",
    "train,val,test = LoadAndPreprocessDataset.loadDatasetFilenames(nCategories=nCategories)\n",
    "\n",
    "#Load TEST file\n",
    "X,y_test=LoadAndPreprocessDataset.loadBatch(test,batch_size=nTestSamples, nCategories=nCategories)\n",
    "\n",
    "\n",
    "\n",
    "#Preprocess TEST\n",
    "#X_test=LoadAndPreprocessDataset.MFCC_DELTA(X,n_mfcc=40)\n",
    "#X_test=LoadAndPreprocessDataset.MFCC(X,n_mfcc=40)\n",
    "#X_test=LoadAndPreprocessDataset.melspect(X)\n",
    "#X_test=X\n",
    "\n",
    "#ADD extra dimension for CNN\n",
    "X_test = X_test[..., np.newaxis]\n",
    "\n",
    "\n",
    "\n",
    "starts=np.empty((len(X),))\n",
    "ends=np.empty((len(X),))\n",
    "for i in range(len(X)):\n",
    "    a=np.array([X[i]])\n",
    "    starts[i]=time.time()\n",
    "    #a=LoadAndPreprocessDataset.MFCC_DELTA(a,n_mfcc=40)\n",
    "    a=LoadAndPreprocessDataset.MFCC(a,n_mfcc=40)\n",
    "    #a=LoadAndPreprocessDataset.melspect(a)\n",
    "    a=a[...,np.newaxis]\n",
    "       \n",
    "    \n",
    "    a=np.argmax(model.predict(a),1)\n",
    "    ends[i]=time.time()\n",
    "average=sum(ends-starts)/len(X_test)\n",
    "print(\"Average single prediction time (ms):\",average*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
